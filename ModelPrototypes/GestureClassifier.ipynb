{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A Classification Model Designed for Multiclass Pose Detection with Scklearn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objective: Given a dataset of coordinates of mediapipe holistic/hand detection solutions, the model is designed to learn from the past gestures on dataset and detect the gestures live on webcam.\r\n",
    "\r\n",
    "## Dataset: There are two types of datasets which can be used with this model.\r\n",
    "\r\n",
    "- Holistic Dataset: The Mediapipe Holistic solutions offer detection of the position of a person's body in a webcam/image frame with 501 point percision with each point haveing x,y,z, visibility coordinates. The holistic solution detects the pose, face and both hands of the person.\r\n",
    "  \r\n",
    "![alt text](https://miro.medium.com/max/1400/1*yerbuR_F4PI7SKyvTneDiA.png \"Pose Solution Model\")\r\n",
    "\r\n",
    "----\r\n",
    "\r\n",
    "- Hand Dataset: The Mediapipe Hands solutions offer detection of the position of a person's hand/hands in a webcam/image frame with 21 point percision with each point haveing x,y, z (depth) coordinates.\r\n",
    "\r\n",
    "![alt text](https://miro.medium.com/max/1400/1*Ytz19eku7HLGiJZysC6Hdg.png \"Hands Solution Model\")\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install and Import Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preproccesing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# import dependencies\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import mediapipe as mp \r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Make a dataframe\r\n",
    "df = pd.read_csv('hands-coords.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "df.groupby(df['class']).count()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         x1    y1    z1    x2    y2    z2    x3    y3    z3    x4  ...   z18  \\\n",
       "class                                                              ...         \n",
       "CLOSE  1430  1430  1430  1430  1430  1430  1430  1430  1430  1430  ...  1430   \n",
       "FUCK    960   960   960   960   960   960   960   960   960   960  ...   960   \n",
       "OPEN   1793  1793  1793  1793  1793  1793  1793  1793  1793  1793  ...  1793   \n",
       "WOLF   1026  1026  1026  1026  1026  1026  1026  1026  1026  1026  ...  1026   \n",
       "\n",
       "        x19   y19   z19   x20   y20   z20   x21   y21   z21  \n",
       "class                                                        \n",
       "CLOSE  1430  1430  1430  1430  1430  1430  1430  1430  1430  \n",
       "FUCK    960   960   960   960   960   960   960   960   960  \n",
       "OPEN   1793  1793  1793  1793  1793  1793  1793  1793  1793  \n",
       "WOLF   1026  1026  1026  1026  1026  1026  1026  1026  1026  \n",
       "\n",
       "[4 rows x 63 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CLOSE</th>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>...</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUCK</th>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>...</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPEN</th>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>...</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "      <td>1793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WOLF</th>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>...</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 63 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5209, 64)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "X = df.drop('class', axis=1) # features\r\n",
    "y = df['class'] # target value"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Split the dataset\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "from sklearn.pipeline import make_pipeline\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "pipelines = {\r\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\r\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\r\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\r\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\r\n",
    "\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "fit_models = {}\r\n",
    "for algo, pipeline in pipelines.items():\r\n",
    "    model = pipeline.fit(X_train, y_train)\r\n",
    "    fit_models[algo] = model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "fit_models"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation and Serialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "from sklearn.metrics import accuracy_score\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Get Model Accuracies\r\n",
    "model_accuracy = {}\r\n",
    "for algo, model in fit_models.items():\r\n",
    "    yhat = model.predict(X_test)\r\n",
    "    model_accuracy[algo] = accuracy_score(y_test, yhat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "model_accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'lr': 0.9980806142034548,\n",
       " 'rc': 0.9929622520793346,\n",
       " 'rf': 0.9987204094689699,\n",
       " 'gb': 0.9980806142034548}"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Choose the best model\r\n",
    "best_model = max(model_accuracy)\r\n",
    "best_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'rf'"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Save the model\r\n",
    "with open('body_language_decoder.pkl', 'wb') as f:\r\n",
    "    pickle.dump(fit_models[best_model], f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Detections with the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "with open('body_language_decoder.pkl', 'rb') as f:\r\n",
    "    model = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Holistic Detections ( Only use with the holistic dataset)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helper\r\n",
    "mp_holistic = mp.solutions.holistic\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "# Initiate holistic model\r\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\r\n",
    "    \r\n",
    "    while cap.isOpened():\r\n",
    "        ret, frame = cap.read()\r\n",
    "        \r\n",
    "        # Recolor Feed\r\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
    "        image.flags.writeable = False        \r\n",
    "        \r\n",
    "        # Make Detections\r\n",
    "        results = holistic.process(image)\r\n",
    "        # print(results.face_landmarks)\r\n",
    "        \r\n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\r\n",
    "        \r\n",
    "        # Recolor image back to BGR for rendering\r\n",
    "        image.flags.writeable = True   \r\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
    "        \r\n",
    "        # 1. Draw face landmarks\r\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS, \r\n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\r\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\r\n",
    "                                 )\r\n",
    "        \r\n",
    "        # 2. Right hand\r\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \r\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\r\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\r\n",
    "                                 )\r\n",
    "\r\n",
    "        # 3. Left Hand\r\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \r\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\r\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\r\n",
    "                                 )\r\n",
    "\r\n",
    "        # 4. Pose Detections\r\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \r\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\r\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\r\n",
    "                                 )\r\n",
    "        # Export coordinates\r\n",
    "        try:\r\n",
    "            # Extract Pose landmarks\r\n",
    "            pose = results.pose_landmarks.landmark\r\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\r\n",
    "            \r\n",
    "            # Extract Face landmarks\r\n",
    "            face = results.face_landmarks.landmark\r\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\r\n",
    "            \r\n",
    "            # Concate rows\r\n",
    "            row = pose_row+face_row\r\n",
    "\r\n",
    "            # Make Detections\r\n",
    "            X = pd.DataFrame([row])\r\n",
    "            body_language_class = model.predict(X)[0]\r\n",
    "            body_language_prob = model.predict_proba(X)[0]\r\n",
    "            \r\n",
    "            # Grab ear coords\r\n",
    "            coords = tuple(np.multiply(\r\n",
    "                            np.array(\r\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \r\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\r\n",
    "                        , [640,480]).astype(int))\r\n",
    "            \r\n",
    "            cv2.rectangle(image, \r\n",
    "                          (coords[0], coords[1]+5), \r\n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \r\n",
    "                          (245, 117, 16), -1)\r\n",
    "            cv2.putText(image, body_language_class, coords, \r\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\r\n",
    "            \r\n",
    "            # Get status box\r\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\r\n",
    "            \r\n",
    "            # Display Class\r\n",
    "            cv2.putText(image, 'CLASS'\r\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\r\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\r\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\r\n",
    "            \r\n",
    "            # Display Probability\r\n",
    "            cv2.putText(image, 'PROB'\r\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\r\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\r\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\r\n",
    "            \r\n",
    "        except:\r\n",
    "            pass\r\n",
    "                        \r\n",
    "        cv2.imshow('Raw Webcam Feed', image)\r\n",
    "\r\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\r\n",
    "            break\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hands Detections ( Only use with the hands dataset)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "import traceback\r\n",
    "\r\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helper\r\n",
    "mp_hands = mp.solutions.hands\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "# Initiate holistic model\r\n",
    "with mp_hands.Hands(max_num_hands=1) as hand:\r\n",
    "\r\n",
    "    while cap.isOpened():\r\n",
    "        ret, frame = cap.read()\r\n",
    "\r\n",
    "        # Recolor the image\r\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
    "        image.flags.writeable = False\r\n",
    "        # Make Detections\r\n",
    "        results = hand.process(image)\r\n",
    "\r\n",
    "        # Landmark detection\r\n",
    "        image.flags.writeable = True\r\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
    "        \r\n",
    "        if results.multi_hand_landmarks:\r\n",
    "            for handLms in results.multi_hand_landmarks:\r\n",
    "                    mp_drawing.draw_landmarks(image, handLms, mp_hands.HAND_CONNECTIONS)\r\n",
    "\r\n",
    "        if results.multi_hand_landmarks:\r\n",
    "            # Export coordinates\r\n",
    "            try:\r\n",
    "                # Extracting hand landmarks\r\n",
    "                detected_hand = results.multi_hand_landmarks[0].landmark\r\n",
    "                row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in detected_hand]).flatten())\r\n",
    "\r\n",
    "                # Make Detections\r\n",
    "                X = pd.DataFrame([row])\r\n",
    "                body_language_class = model.predict(X)[0]\r\n",
    "                body_language_prob = model.predict_proba(X)[0]\r\n",
    "                \r\n",
    "                # Get status box\r\n",
    "                cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\r\n",
    "                \r\n",
    "                # Display Class\r\n",
    "                cv2.putText(image, 'CLASS'\r\n",
    "                            , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\r\n",
    "                cv2.putText(image, body_language_class.split(' ')[0]\r\n",
    "                            , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\r\n",
    "                \r\n",
    "                # Display Probability\r\n",
    "                cv2.putText(image, 'PROB'\r\n",
    "                            , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\r\n",
    "                cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\r\n",
    "                            , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\r\n",
    "                \r\n",
    "            except:\r\n",
    "                traceback.print_exc()\r\n",
    "                            \r\n",
    "        cv2.imshow('Raw Webcam Feed', image)\r\n",
    "\r\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\r\n",
    "            break\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1df6b99b5e9756eed4e22fb0d124bf8d9f8552b372ae034d7c6b29f98bd0c98b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}